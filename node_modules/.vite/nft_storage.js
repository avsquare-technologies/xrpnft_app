import {
  BaseBlockstore,
  CID,
  CarWriter,
  Token,
  TreewalkCarSplitter,
  Type,
  decode2 as decode,
  encode,
  encode2,
  importer,
  init_cid,
  init_sha2_browser,
  init_src,
  normaliseInput,
  normaliseInput2,
  require_it_last,
  require_it_pipe,
  require_p_retry,
  require_throttledQueue,
  sha256,
  transform
} from "./chunk-JYZO6WQE.js";
import {
  __export,
  __objRest,
  __spreadProps,
  __spreadValues,
  __toESM
} from "./chunk-IGMYUX52.js";

// node_modules/nft.storage/src/lib.js
var import_p_retry = __toESM(require_p_retry(), 1);

// node_modules/nft.storage/node_modules/ipfs-car/dist/esm/pack/index.js
var import_it_last = __toESM(require_it_last());
var import_it_pipe = __toESM(require_it_pipe());

// node_modules/nft.storage/node_modules/ipfs-car/dist/esm/pack/utils/normalise-input.js
function isBytes(obj) {
  return ArrayBuffer.isView(obj) || obj instanceof ArrayBuffer;
}
function isBlob(obj) {
  return Boolean(obj.constructor) && (obj.constructor.name === "Blob" || obj.constructor.name === "File") && typeof obj.stream === "function";
}
function isSingle(input) {
  return typeof input === "string" || input instanceof String || isBytes(input) || isBlob(input) || "_readableState" in input;
}
function getNormaliser(input) {
  if (isSingle(input)) {
    return normaliseInput(input);
  } else {
    return normaliseInput2(input);
  }
}

// node_modules/nft.storage/node_modules/ipfs-car/dist/esm/blockstore/memory.js
init_src();
var MemoryBlockStore = class extends BaseBlockstore {
  constructor() {
    super();
    this.store = /* @__PURE__ */ new Map();
  }
  async *blocks() {
    for (const [cidStr, bytes] of this.store.entries()) {
      yield { cid: CID.parse(cidStr), bytes };
    }
  }
  put(cid, bytes) {
    this.store.set(cid.toString(), bytes);
    return Promise.resolve();
  }
  get(cid) {
    const bytes = this.store.get(cid.toString());
    if (!bytes) {
      throw new Error(`block with cid ${cid.toString()} no found`);
    }
    return Promise.resolve(bytes);
  }
  has(cid) {
    return Promise.resolve(this.store.has(cid.toString()));
  }
  close() {
    this.store.clear();
    return Promise.resolve();
  }
};

// node_modules/nft.storage/node_modules/ipfs-car/dist/esm/pack/constants.js
init_sha2_browser();
var unixfsImporterOptionsDefault = {
  cidVersion: 1,
  chunker: "fixed",
  maxChunkSize: 262144,
  hasher: sha256,
  rawLeaves: true,
  wrapWithDirectory: true,
  maxChildrenPerNode: 174
};

// node_modules/nft.storage/node_modules/ipfs-car/dist/esm/pack/index.js
async function pack({ input, blockstore: userBlockstore, hasher, maxChunkSize, maxChildrenPerNode, wrapWithDirectory, rawLeaves }) {
  if (!input || Array.isArray(input) && !input.length) {
    throw new Error("missing input file(s)");
  }
  const blockstore = userBlockstore ? userBlockstore : new MemoryBlockStore();
  const rootEntry = await (0, import_it_last.default)((0, import_it_pipe.default)(getNormaliser(input), (source) => importer(source, blockstore, __spreadProps(__spreadValues({}, unixfsImporterOptionsDefault), {
    hasher: hasher || unixfsImporterOptionsDefault.hasher,
    maxChunkSize: maxChunkSize || unixfsImporterOptionsDefault.maxChunkSize,
    maxChildrenPerNode: maxChildrenPerNode || unixfsImporterOptionsDefault.maxChildrenPerNode,
    wrapWithDirectory: wrapWithDirectory === false ? false : unixfsImporterOptionsDefault.wrapWithDirectory,
    rawLeaves: rawLeaves == null ? unixfsImporterOptionsDefault.rawLeaves : rawLeaves
  }))));
  if (!rootEntry || !rootEntry.cid) {
    throw new Error("given input could not be parsed correctly");
  }
  const root = rootEntry.cid;
  const { writer, out: carOut } = await CarWriter.create([root]);
  const carOutIter = carOut[Symbol.asyncIterator]();
  let writingPromise;
  const writeAll = async () => {
    for await (const block of blockstore.blocks()) {
      await writer.put(block);
    }
    await writer.close();
    if (!userBlockstore) {
      await blockstore.close();
    }
  };
  const out = {
    [Symbol.asyncIterator]() {
      if (writingPromise != null) {
        throw new Error("Multiple iterator not supported");
      }
      writingPromise = writeAll();
      return {
        async next() {
          const result = await carOutIter.next();
          if (result.done) {
            await writingPromise;
          }
          return result;
        }
      };
    }
  };
  return { root, out };
}

// node_modules/nft.storage/src/lib.js
init_cid();
var import_throttled_queue = __toESM(require_throttledQueue(), 1);

// node_modules/nft.storage/src/token.js
var token_exports = {};
__export(token_exports, {
  Token: () => Token2,
  decode: () => decode3,
  embed: () => embed,
  encode: () => encode4,
  mapWith: () => mapWith
});
init_cid();
init_sha2_browser();

// node_modules/nft.storage/node_modules/@ipld/dag-cbor/esm/index.js
var esm_exports = {};
__export(esm_exports, {
  code: () => code,
  decode: () => decode2,
  encode: () => encode3,
  name: () => name
});
init_cid();
var CID_CBOR_TAG = 42;
function cidEncoder(obj) {
  if (obj.asCID !== obj) {
    return null;
  }
  const cid = CID.asCID(obj);
  if (!cid) {
    return null;
  }
  const bytes = new Uint8Array(cid.bytes.byteLength + 1);
  bytes.set(cid.bytes, 1);
  return [
    new Token(Type.tag, CID_CBOR_TAG),
    new Token(Type.bytes, bytes)
  ];
}
function undefinedEncoder() {
  throw new Error("`undefined` is not supported by the IPLD Data Model and cannot be encoded");
}
function numberEncoder(num) {
  if (Number.isNaN(num)) {
    throw new Error("`NaN` is not supported by the IPLD Data Model and cannot be encoded");
  }
  if (num === Infinity || num === -Infinity) {
    throw new Error("`Infinity` and `-Infinity` is not supported by the IPLD Data Model and cannot be encoded");
  }
  return null;
}
var encodeOptions = {
  float64: true,
  typeEncoders: {
    Object: cidEncoder,
    undefined: undefinedEncoder,
    number: numberEncoder
  }
};
function cidDecoder(bytes) {
  if (bytes[0] !== 0) {
    throw new Error("Invalid CID for CBOR tag 42; expected leading 0x00");
  }
  return CID.decode(bytes.subarray(1));
}
var decodeOptions = {
  allowIndefinite: false,
  allowUndefined: false,
  allowNaN: false,
  allowInfinity: false,
  allowBigInt: true,
  strict: true,
  useMaps: false,
  tags: []
};
decodeOptions.tags[CID_CBOR_TAG] = cidDecoder;
var name = "dag-cbor";
var code = 113;
var encode3 = (node) => encode(node, encodeOptions);
var decode2 = (data) => decode(data, decodeOptions);

// node_modules/nft.storage/src/platform.web.js
var fetch = globalThis.fetch;
var FormData = globalThis.FormData;
var Headers = globalThis.Headers;
var Request = globalThis.Request;
var Response = globalThis.Response;
var Blob = globalThis.Blob;
var File = globalThis.File;
var ReadableStream = globalThis.ReadableStream;
var Blockstore = MemoryBlockStore;

// node_modules/nft.storage/src/gateway.js
var GATEWAY = new URL("https://nftstorage.link/");
var toGatewayURL = (url, options = {}) => {
  const gateway = options.gateway || GATEWAY;
  url = new URL(String(url));
  return url.protocol === "ipfs:" ? new URL(`/ipfs/${url.href.slice("ipfs://".length)}`, gateway) : url;
};

// node_modules/nft.storage/src/bs-car-reader.js
var BlockstoreCarReader = class {
  constructor(version, roots, blockstore) {
    this._version = version;
    this._roots = roots;
    this._blockstore = blockstore;
  }
  get version() {
    return this._version;
  }
  get blockstore() {
    return this._blockstore;
  }
  async getRoots() {
    return this._roots;
  }
  has(cid) {
    return this._blockstore.has(cid);
  }
  async get(cid) {
    const bytes = await this._blockstore.get(cid);
    return { cid, bytes };
  }
  blocks() {
    return this._blockstore.blocks();
  }
  async *cids() {
    for await (const b of this.blocks()) {
      yield b.cid;
    }
  }
};

// node_modules/nft.storage/src/token.js
var Token2 = class {
  constructor(ipnft, url, data) {
    this.ipnft = ipnft;
    this.url = url;
    this.data = data;
    Object.defineProperties(this, {
      ipnft: { enumerable: true, writable: false },
      url: { enumerable: true, writable: false },
      data: { enumerable: false, writable: false }
    });
  }
  embed() {
    return Token2.embed(this);
  }
  static embed({ data }) {
    return embed(data, { gateway: GATEWAY });
  }
  static async encode(input) {
    const blockstore = new Blockstore();
    const [blobs, meta] = mapTokenInputBlobs(input);
    const data = JSON.parse(JSON.stringify(meta));
    const dag = JSON.parse(JSON.stringify(meta));
    for (const [dotPath, blob] of blobs.entries()) {
      const name2 = blob.name || "blob";
      const content = blob.stream();
      const { root: cid } = await pack({
        input: [{ path: name2, content }],
        blockstore,
        wrapWithDirectory: true
      });
      const href = new URL(`ipfs://${cid}/${name2}`);
      const path = dotPath.split(".");
      setIn(data, path, href);
      setIn(dag, path, cid);
    }
    const { root: metadataJsonCid } = await pack({
      input: [{ path: "metadata.json", content: JSON.stringify(data) }],
      blockstore,
      wrapWithDirectory: false
    });
    const block = await encode2({
      value: __spreadProps(__spreadValues({}, dag), {
        "metadata.json": metadataJsonCid,
        type: "nft"
      }),
      codec: esm_exports,
      hasher: sha256
    });
    await blockstore.put(block.cid, block.bytes);
    return {
      cid: block.cid,
      token: new Token2(block.cid.toString(), `ipfs://${block.cid}/metadata.json`, data),
      car: new BlockstoreCarReader(1, [block.cid], blockstore)
    };
  }
};
var embed = (input, options) => mapWith(input, isURL, embedURL, options);
var decode3 = ({ ipnft, url, data }, paths) => new Token2(ipnft, url, mapWith(data, isEncodedURL, decodeURL, paths));
var isURL = (value) => value instanceof URL;
var decodeURL = (state, url) => [state, new URL(url)];
var embedURL = (context, url) => [context, toGatewayURL(url, context)];
var isObject = (value) => typeof value === "object" && value != null;
var isEncodedURL = (value, assetPaths, path) => typeof value === "string" && assetPaths.has(path.join("."));
var encode4 = (input) => {
  const [map, meta] = mapValueWith(input, isBlob2, encodeBlob, /* @__PURE__ */ new Map(), []);
  const form = new FormData();
  for (const [k, v] of map.entries()) {
    form.set(k, v);
  }
  form.set("meta", JSON.stringify(meta));
  return form;
};
var encodeBlob = (data, blob, path) => {
  data.set(path.join("."), blob);
  return [data, void 0];
};
var isBlob2 = (value) => value instanceof Blob;
var mapTokenInputBlobs = (input) => {
  return mapValueWith(input, isBlob2, encodeBlob, /* @__PURE__ */ new Map(), []);
};
var mapWith = (input, p, f, state) => {
  const [, output] = mapValueWith(input, p, f, state, []);
  return output;
};
var mapValueWith = (input, p, f, state, path) => p(input, state, path) ? f(state, input, path) : Array.isArray(input) ? mapArrayWith(input, p, f, state, path) : isObject(input) ? mapObjectWith(input, p, f, state, path) : [state, input];
var mapObjectWith = (input, p, f, init, path) => {
  let state = init;
  const output = {};
  for (const [key, value] of Object.entries(input)) {
    const [next, out] = mapValueWith(value, p, f, state, [...path, key]);
    output[key] = out;
    state = next;
  }
  return [state, output];
};
var mapArrayWith = (input, p, f, init, path) => {
  const output = [];
  let state = init;
  for (const [index, element] of input.entries()) {
    const [next, out] = mapValueWith(element, p, f, state, [...path, index]);
    output[index] = out;
    state = next;
  }
  return [
    state,
    output
  ];
};
var setIn = (object, path, value) => {
  const n = path.length - 1;
  let target = object;
  for (let [index, key] of path.entries()) {
    if (index === n) {
      target[key] = value;
    } else {
      target = target[key];
    }
  }
};

// node_modules/nft.storage/src/lib.js
var import_it_pipe2 = __toESM(require_it_pipe(), 1);
var MAX_STORE_RETRIES = 5;
var MAX_CONCURRENT_UPLOADS = 3;
var MAX_CHUNK_SIZE = 1024 * 1024 * 10;
var RATE_LIMIT_REQUESTS = 30;
var RATE_LIMIT_PERIOD = 10 * 1e3;
function createRateLimiter() {
  const throttle = (0, import_throttled_queue.default)(RATE_LIMIT_REQUESTS, RATE_LIMIT_PERIOD);
  return () => throttle(() => {
  });
}
var globalRateLimiter = createRateLimiter();
var NFTStorage = class {
  constructor({
    token,
    did,
    endpoint = new URL("https://api.nft.storage"),
    rateLimiter
  }) {
    this.token = token;
    this.endpoint = endpoint;
    this.rateLimiter = rateLimiter || createRateLimiter();
    this.did = did;
  }
  static auth({ token, did }) {
    if (!token)
      throw new Error("missing token");
    return __spreadValues({
      Authorization: `Bearer ${token}`,
      "X-Client": "nft.storage/js"
    }, did ? { "x-agent-did": did } : {});
  }
  static async storeBlob(service, blob, options) {
    const blockstore = new Blockstore();
    let cidString;
    try {
      const { cid, car } = await NFTStorage.encodeBlob(blob, { blockstore });
      await NFTStorage.storeCar(service, car, options);
      cidString = cid.toString();
    } finally {
      await blockstore.close();
    }
    return cidString;
  }
  static async storeCar(_a, car, { onStoredChunk, maxRetries, decoders, signal } = {}) {
    var _b = _a, { endpoint, rateLimiter = globalRateLimiter } = _b, token = __objRest(_b, ["endpoint", "rateLimiter"]);
    const url = new URL("upload/", endpoint);
    const headers = NFTStorage.auth(token);
    const targetSize = MAX_CHUNK_SIZE;
    const splitter = car instanceof Blob ? await TreewalkCarSplitter.fromBlob(car, targetSize, { decoders }) : new TreewalkCarSplitter(car, targetSize, { decoders });
    const upload = transform(MAX_CONCURRENT_UPLOADS, async function(car2) {
      const carParts = [];
      for await (const part of car2) {
        carParts.push(part);
      }
      const carFile = new Blob(carParts, { type: "application/car" });
      const cid = await (0, import_p_retry.default)(async () => {
        await rateLimiter();
        let response;
        try {
          response = await fetch(url.toString(), {
            method: "POST",
            headers,
            body: carFile,
            signal
          });
        } catch (err) {
          throw signal && signal.aborted ? new import_p_retry.AbortError(err) : err;
        }
        if (response.status === 429) {
          throw new Error("rate limited");
        }
        const result = await response.json();
        if (!result.ok) {
          if (response.status === 401) {
            throw new import_p_retry.AbortError(result.error.message);
          }
          throw new Error(result.error.message);
        }
        return result.value.cid;
      }, {
        retries: maxRetries == null ? MAX_STORE_RETRIES : maxRetries
      });
      onStoredChunk && onStoredChunk(carFile.size);
      return cid;
    });
    let root;
    for await (const cid of upload(splitter.cars())) {
      root = cid;
    }
    return root;
  }
  static async storeDirectory(service, filesSource, options) {
    const blockstore = new Blockstore();
    let cidString;
    try {
      const { cid, car } = await NFTStorage.encodeDirectory(filesSource, {
        blockstore
      });
      await NFTStorage.storeCar(service, car, options);
      cidString = cid.toString();
    } finally {
      await blockstore.close();
    }
    return cidString;
  }
  static async store(service, metadata, options) {
    const { token, car } = await NFTStorage.encodeNFT(metadata);
    await NFTStorage.storeCar(service, car, options);
    return token;
  }
  static async status(_c, cid, options) {
    var _d = _c, { endpoint, rateLimiter = globalRateLimiter } = _d, token = __objRest(_d, ["endpoint", "rateLimiter"]);
    const url = new URL(`${cid}/`, endpoint);
    await rateLimiter();
    const response = await fetch(url.toString(), {
      method: "GET",
      headers: NFTStorage.auth(token),
      signal: options && options.signal
    });
    if (response.status === 429) {
      throw new Error("rate limited");
    }
    const result = await response.json();
    if (result.ok) {
      return {
        cid: result.value.cid,
        deals: decodeDeals(result.value.deals),
        size: result.value.size,
        pin: decodePin(result.value.pin),
        created: new Date(result.value.created)
      };
    } else {
      throw new Error(result.error.message);
    }
  }
  static async check({ endpoint, rateLimiter = globalRateLimiter }, cid, options) {
    const url = new URL(`check/${cid}/`, endpoint);
    await rateLimiter();
    const response = await fetch(url.toString(), {
      signal: options && options.signal
    });
    if (response.status === 429) {
      throw new Error("rate limited");
    }
    const result = await response.json();
    if (result.ok) {
      return {
        cid: result.value.cid,
        deals: decodeDeals(result.value.deals),
        pin: result.value.pin
      };
    } else {
      throw new Error(result.error.message);
    }
  }
  static async delete(_e, cid, options) {
    var _f = _e, { endpoint, rateLimiter = globalRateLimiter } = _f, token = __objRest(_f, ["endpoint", "rateLimiter"]);
    const url = new URL(`${cid}/`, endpoint);
    await rateLimiter();
    const response = await fetch(url.toString(), {
      method: "DELETE",
      headers: NFTStorage.auth(token),
      signal: options && options.signal
    });
    if (response.status === 429) {
      throw new Error("rate limited");
    }
    const result = await response.json();
    if (!result.ok) {
      throw new Error(result.error.message);
    }
  }
  static async encodeNFT(input) {
    validateERC1155(input);
    return Token2.encode(input);
  }
  static async encodeBlob(blob, { blockstore } = {}) {
    if (blob.size === 0) {
      throw new Error("Content size is 0, make sure to provide some content");
    }
    return packCar([toImportCandidate("blob", blob)], {
      blockstore,
      wrapWithDirectory: false
    });
  }
  static async encodeDirectory(files, { blockstore } = {}) {
    let size = 0;
    const input = (0, import_it_pipe2.default)(files, async function* (files2) {
      for await (const file of files2) {
        yield toImportCandidate(file.name, file);
        size += file.size;
      }
    });
    const packed = await packCar(input, {
      blockstore,
      wrapWithDirectory: true
    });
    if (size === 0) {
      throw new Error("Total size of files should exceed 0, make sure to provide some content");
    }
    return packed;
  }
  storeBlob(blob, options) {
    return NFTStorage.storeBlob(this, blob, options);
  }
  storeCar(car, options) {
    return NFTStorage.storeCar(this, car, options);
  }
  storeDirectory(files, options) {
    return NFTStorage.storeDirectory(this, files, options);
  }
  status(cid, options) {
    return NFTStorage.status(this, cid, options);
  }
  delete(cid, options) {
    return NFTStorage.delete(this, cid, options);
  }
  check(cid, options) {
    return NFTStorage.check(this, cid, options);
  }
  store(token, options) {
    return NFTStorage.store(this, token, options);
  }
};
function toAsyncIterable(iterable) {
  return async function* () {
    for (const item of iterable) {
      yield item;
    }
  }();
}
var validateERC1155 = ({ name: name2, description, image, decimals }) => {
  if (typeof name2 !== "string") {
    throw new TypeError("string property `name` identifying the asset is required");
  }
  if (typeof description !== "string") {
    throw new TypeError("string property `description` describing asset is required");
  }
  if (!(image instanceof Blob)) {
    throw new TypeError("property `image` must be a Blob or File object");
  } else if (!image.type.startsWith("image/")) {
    console.warn(`According to ERC721 Metadata JSON Schema 'image' must have 'image/*' mime type.

For better interoperability we would highly recommend storing content with different mime type under 'properties' namespace e.g. \`properties: { video: file }\` and using 'image' field for storing a preview image for it instead.

For more context please see ERC-721 specification https://eips.ethereum.org/EIPS/eip-721`);
  }
  if (typeof decimals !== "undefined" && typeof decimals !== "number") {
    throw new TypeError("property `decimals` must be an integer value");
  }
};
var packCar = async (input, { blockstore, wrapWithDirectory } = {}) => {
  blockstore = blockstore || new Blockstore();
  const { root: cid } = await pack({ input, blockstore, wrapWithDirectory });
  const car = new BlockstoreCarReader(1, [cid], blockstore);
  return { cid, car };
};
var decodeDeals = (deals) => deals.map((deal) => {
  const { dealActivation, dealExpiration, lastChanged } = __spreadValues({
    dealExpiration: null,
    dealActivation: null
  }, deal);
  return __spreadValues(__spreadValues(__spreadProps(__spreadValues({}, deal), {
    lastChanged: new Date(lastChanged)
  }), dealActivation && { dealActivation: new Date(dealActivation) }), dealExpiration && { dealExpiration: new Date(dealExpiration) });
});
var decodePin = (pin) => __spreadProps(__spreadValues({}, pin), { created: new Date(pin.created) });
function toImportCandidate(path, blob) {
  let stream;
  return {
    path,
    get content() {
      stream = stream || blob.stream();
      return stream;
    }
  };
}
export {
  Blob,
  File,
  FormData,
  NFTStorage,
  token_exports as Token,
  createRateLimiter,
  toAsyncIterable,
  toGatewayURL
};
//# sourceMappingURL=nft_storage.js.map
